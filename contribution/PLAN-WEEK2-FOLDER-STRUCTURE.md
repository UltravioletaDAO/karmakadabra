# Week 2: Self-Contained Folder Structure Plan

**Date:** October 28, 2025
**Goal:** Make `contribution/` folder completely self-contained and portable
**Reason:** This folder will be packaged for EIP-8004 contribution submission

---

## Design Principles

1. ‚úÖ **Self-contained:** All code, scripts, and dependencies in `contribution/`
2. ‚úÖ **Portable:** Can be zipped and run on another machine
3. ‚úÖ **No external deps:** Don't rely on `/shared/` or `/scripts/` outside contribution
4. ‚úÖ **Documented:** Everything has README explaining what it does
5. ‚úÖ **Reproducible:** Anyone can run the same tests and get same results

---

## Proposed Folder Structure

```
contribution/
‚îú‚îÄ‚îÄ README.md                           # Overview of the contribution package
‚îú‚îÄ‚îÄ PLAN-WEEK2-FOLDER-STRUCTURE.md     # This file (the plan)
‚îÇ
‚îú‚îÄ‚îÄ 0-MASTER-PLAN.md                    # Overall roadmap (exists)
‚îú‚îÄ‚îÄ 0.1-GETTING-STARTED.md              # Setup guide (exists)
‚îú‚îÄ‚îÄ 0.2-PROGRESS-TRACKER.md             # Daily progress (exists)
‚îú‚îÄ‚îÄ 00-FILE-INDEX.md                    # Navigation guide (exists)
‚îÇ
‚îú‚îÄ‚îÄ week1/                              # Week 1 deliverables (complete)
‚îÇ   ‚îú‚îÄ‚îÄ 1.0-CHECKLIST.md
‚îÇ   ‚îú‚îÄ‚îÄ 1.1-DAY1-SUMMARY.md
‚îÇ   ‚îú‚îÄ‚îÄ 1.2-DAY2-TEST-RESULTS.md
‚îÇ   ‚îú‚îÄ‚îÄ 1.3-DAY3-PYTHON-IMPLEMENTATION.md
‚îÇ   ‚îú‚îÄ‚îÄ 1.4-DAY4-INTEGRATION-TESTS.md
‚îÇ   ‚îî‚îÄ‚îÄ 1.5-DAY5-EVIDENCE-PACKAGE.md
‚îÇ
‚îú‚îÄ‚îÄ week2/                              # Week 2 work (current)
‚îÇ   ‚îú‚îÄ‚îÄ 2.0-CHECKLIST.md                # ‚úÖ Created
‚îÇ   ‚îú‚îÄ‚îÄ 2.1-GETTING-STARTED.md          # ‚úÖ Created
‚îÇ   ‚îú‚îÄ‚îÄ 2.2-DAY1-SIMULATION-DESIGN.md   # TODO
‚îÇ   ‚îú‚îÄ‚îÄ 2.3-DAY2-SCRIPT-IMPLEMENTATION.md  # TODO
‚îÇ   ‚îú‚îÄ‚îÄ 2.4-DAY3-EXECUTION-RESULTS.md   # TODO
‚îÇ   ‚îú‚îÄ‚îÄ 2.5-DAY4-ANALYSIS.md            # TODO
‚îÇ   ‚îú‚îÄ‚îÄ 2.6-DAY5-EDGE-CASES.md          # TODO
‚îÇ   ‚îî‚îÄ‚îÄ data/                           # Transaction data outputs
‚îÇ       ‚îú‚îÄ‚îÄ transactions.csv            # All 100+ transactions
‚îÇ       ‚îú‚îÄ‚îÄ transaction_hashes.txt      # On-chain proof
‚îÇ       ‚îú‚îÄ‚îÄ screenshots/                # Snowtrace screenshots
‚îÇ       ‚îî‚îÄ‚îÄ analysis/                   # Statistical analysis outputs
‚îÇ
‚îú‚îÄ‚îÄ scripts/                            # üÜï Self-contained scripts
‚îÇ   ‚îú‚îÄ‚îÄ README.md                       # What each script does
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt                # Python dependencies
‚îÇ   ‚îú‚îÄ‚îÄ simulate_marketplace.py         # Main simulation script
‚îÇ   ‚îú‚îÄ‚îÄ verify_system_ready.py          # Check 54 agents ready
‚îÇ   ‚îú‚îÄ‚îÄ analyze_ratings.py              # Statistical analysis
‚îÇ   ‚îú‚îÄ‚îÄ export_transactions.py          # Export to CSV
‚îÇ   ‚îî‚îÄ‚îÄ utils/                          # Helper utilities
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ agent_loader.py             # Load agent configs
‚îÇ       ‚îú‚îÄ‚îÄ transaction_logger.py       # Log transactions
‚îÇ       ‚îî‚îÄ‚îÄ web3_helper.py              # Web3 utilities
‚îÇ
‚îú‚îÄ‚îÄ shared/                             # üÜï Copied dependencies (minimal)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ agent_config.py                 # Copy from /shared/
‚îÇ   ‚îú‚îÄ‚îÄ base_agent.py                   # Copy from /shared/ (or reference key methods)
‚îÇ   ‚îú‚îÄ‚îÄ secrets_manager.py              # Copy from /shared/
‚îÇ   ‚îî‚îÄ‚îÄ README.md                       # Explains what's copied
‚îÇ
‚îú‚îÄ‚îÄ contracts/                          # üÜï Contract code for reference
‚îÇ   ‚îú‚îÄ‚îÄ ReputationRegistry.sol          # The modified contract
‚îÇ   ‚îú‚îÄ‚îÄ ReputationRegistry.abi.json     # ABI for interactions
‚îÇ   ‚îú‚îÄ‚îÄ deployed_addresses.json         # Contract addresses on Fuji
‚îÇ   ‚îî‚îÄ‚îÄ README.md                       # Deployment info
‚îÇ
‚îú‚îÄ‚îÄ tests/                              # üÜï Week 2 specific tests
‚îÇ   ‚îú‚îÄ‚îÄ test_simulation_script.py       # Test the simulator
‚îÇ   ‚îú‚îÄ‚îÄ test_rating_methods.py          # Test bidirectional methods
‚îÇ   ‚îî‚îÄ‚îÄ test_data_analysis.py           # Test analysis functions
‚îÇ
‚îú‚îÄ‚îÄ data/                               # üÜï All data outputs (Week 2+)
‚îÇ   ‚îú‚îÄ‚îÄ week2/                          # Week 2 transaction data
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transactions.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ raw_data.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ analysis_results.json
‚îÇ   ‚îú‚îÄ‚îÄ week3/                          # Week 3 security data
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îú‚îÄ‚îÄ analysis/                           # üÜï Analysis notebooks & results
‚îÇ   ‚îú‚îÄ‚îÄ rating_patterns.ipynb           # Jupyter notebook
‚îÇ   ‚îú‚îÄ‚îÄ statistical_summary.md          # Text summary
‚îÇ   ‚îú‚îÄ‚îÄ visualizations/                 # Charts and graphs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rating_correlation.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ network_graph.html
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ histograms.png
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îú‚îÄ‚îÄ plans/                              # üÜï Detailed execution plans
‚îÇ   ‚îú‚îÄ‚îÄ week2-implementation-plan.md    # Detailed Week 2 plan
‚îÇ   ‚îú‚îÄ‚îÄ simulation-scenarios.md         # Transaction scenarios
‚îÇ   ‚îî‚îÄ‚îÄ data-analysis-plan.md           # Analysis methodology
‚îÇ
‚îú‚îÄ‚îÄ docs/                               # üÜï Supporting documentation
‚îÇ   ‚îú‚îÄ‚îÄ SETUP.md                        # How to run everything
‚îÇ   ‚îú‚îÄ‚îÄ DEPENDENCIES.md                 # What's needed
‚îÇ   ‚îú‚îÄ‚îÄ TESTING.md                      # How to test
‚îÇ   ‚îî‚îÄ‚îÄ TROUBLESHOOTING.md              # Common issues
‚îÇ
‚îî‚îÄ‚îÄ .env.example                        # üÜï Example configuration
```

---

## What Needs to Be Created

### Immediate (Week 2 Start)

#### 1. `contribution/scripts/` folder
**Purpose:** All executable scripts for Week 2

**Files to create:**
- `README.md` - What each script does
- `requirements.txt` - Python dependencies (web3, pandas, matplotlib, etc.)
- `simulate_marketplace.py` - Main simulation script
- `verify_system_ready.py` - Check all 54 agents are ready
- `analyze_ratings.py` - Statistical analysis of results
- `export_transactions.py` - Export data to CSV

#### 2. `contribution/shared/` folder
**Purpose:** Minimal dependencies copied from main repo

**Files to copy:**
- `agent_config.py` - From `/shared/agent_config.py`
- `base_agent.py` - From `/shared/base_agent.py` (or document key methods)
- `secrets_manager.py` - From `/shared/secrets_manager.py`
- `README.md` - Explain what's copied and why

#### 3. `contribution/contracts/` folder
**Purpose:** Contract code for reference

**Files to create:**
- `ReputationRegistry.sol` - Copy from `/erc-8004/contracts/src/`
- `ReputationRegistry.abi.json` - Extract ABI
- `deployed_addresses.json` - Contract addresses
- `README.md` - Deployment information

#### 4. `contribution/plans/` folder
**Purpose:** Detailed implementation plans

**Files to create:**
- `week2-implementation-plan.md` - Detailed Week 2 execution plan
- `simulation-scenarios.md` - All 6 transaction scenarios detailed
- `data-analysis-plan.md` - How we'll analyze the data

#### 5. `contribution/docs/` folder
**Purpose:** Setup and usage documentation

**Files to create:**
- `SETUP.md` - How to set up the environment
- `DEPENDENCIES.md` - Required packages and tools
- `TESTING.md` - How to run tests
- `TROUBLESHOOTING.md` - Common issues and solutions

---

## Dependencies to Document

### Python Packages (for `scripts/requirements.txt`)
```txt
web3>=6.0.0
eth-account>=0.8.0
python-dotenv>=1.0.0
pandas>=2.0.0
matplotlib>=3.7.0
seaborn>=0.12.0
jupyter>=1.0.0
requests>=2.31.0
```

### External Dependencies
- Python 3.9+
- Access to Avalanche Fuji RPC
- AWS credentials (for Secrets Manager) OR local .env with keys
- 54 agent .env files (in main repo, referenced)

---

## Data Flow Design

### Input Data
```
Main Repo ‚Üí contribution/
- Agent addresses (from /client-agents/*/. env)
- Contract addresses (from /erc-8004/.env.fuji)
- Base agent code (copied to contribution/shared/)
```

### Processing
```
contribution/scripts/simulate_marketplace.py
  ‚Üì
Executes 100+ transactions on Fuji testnet
  ‚Üì
Logs to contribution/week2/data/transactions.csv
```

### Analysis
```
contribution/scripts/analyze_ratings.py
  ‚Üì
Reads contribution/week2/data/transactions.csv
  ‚Üì
Outputs to contribution/analysis/
```

### Outputs
```
contribution/week2/
  ‚îú‚îÄ‚îÄ data/transactions.csv           # Raw data
  ‚îú‚îÄ‚îÄ 2.4-DAY4-ANALYSIS.md            # Text analysis
  ‚îî‚îÄ‚îÄ 2.6-DAY5-EDGE-CASES.md          # Documented cases

contribution/analysis/
  ‚îú‚îÄ‚îÄ rating_patterns.ipynb            # Interactive analysis
  ‚îú‚îÄ‚îÄ statistical_summary.md           # Key findings
  ‚îî‚îÄ‚îÄ visualizations/*.png             # Charts
```

---

## Scripts to Create - Detailed

### 1. `scripts/simulate_marketplace.py`
**Purpose:** Execute 100+ transactions with bidirectional ratings

**Functions:**
```python
def load_agents() -> list[ERC8004BaseAgent]:
    """Load all 54 agent configs from main repo"""

def scenario_good_transaction(buyer, seller) -> dict:
    """Simulate mutual 5/5 ratings"""

def scenario_bad_client(buyer, seller) -> dict:
    """Simulate seller rates client low"""

def scenario_bad_seller(buyer, seller) -> dict:
    """Simulate client rates seller low"""

def scenario_disputed(buyer, seller) -> dict:
    """Simulate asymmetric ratings"""

def scenario_validator_rating(seller, validator) -> dict:
    """Simulate seller rating validator"""

def execute_scenario(scenario_func, agents, count=20) -> list[dict]:
    """Execute a scenario N times with different agent pairs"""

def export_to_csv(transactions, filepath):
    """Export all transaction data to CSV"""

def main():
    """Main execution: run all scenarios and export data"""
```

**Command-line interface:**
```bash
# Dry run (no transactions)
python scripts/simulate_marketplace.py --dry-run

# Execute 100 transactions
python scripts/simulate_marketplace.py --execute --count 100

# Execute specific scenario
python scripts/simulate_marketplace.py --scenario bad_client --count 20
```

### 2. `scripts/verify_system_ready.py`
**Purpose:** Verify all 54 agents are registered and funded

**Functions:**
```python
def check_agent_registration(agent_address) -> bool:
    """Check if agent is registered on-chain"""

def check_agent_balance(agent_address) -> dict:
    """Check AVAX and GLUE balances"""

def verify_all_agents() -> dict:
    """Check all 54 agents, return summary"""

def main():
    """Print verification report"""
```

### 3. `scripts/analyze_ratings.py`
**Purpose:** Statistical analysis of transaction data

**Functions:**
```python
def load_transactions(csv_path) -> pd.DataFrame:
    """Load transaction CSV into pandas"""

def calculate_correlation(df) -> float:
    """Calculate buyer vs seller rating correlation"""

def find_asymmetric_ratings(df, threshold=2) -> pd.DataFrame:
    """Find transactions with rating difference > threshold"""

def generate_visualizations(df, output_dir):
    """Create histograms, scatter plots, network graphs"""

def export_summary(analysis_results, output_path):
    """Export markdown summary"""
```

---

## Execution Plan - Week 2

### Day 1 (4 hours): Setup & Design
**Tasks:**
- [ ] Create folder structure
- [ ] Copy dependencies to `contribution/shared/`
- [ ] Copy contract code to `contribution/contracts/`
- [ ] Create `contribution/scripts/requirements.txt`
- [ ] Write detailed simulation scenarios in `plans/simulation-scenarios.md`
- [ ] Write `docs/SETUP.md` for how to run everything

**Output:** Complete folder structure, no execution yet

### Day 2 (4 hours): Implement Simulation Script
**Tasks:**
- [ ] Implement `scripts/simulate_marketplace.py`
- [ ] Implement scenario functions (all 6)
- [ ] Implement transaction logging
- [ ] Implement CSV export
- [ ] Test with `--dry-run` mode

**Output:** Working simulation script (tested, not executed)

### Day 3 (4 hours): Execute Transactions
**Tasks:**
- [ ] Run `verify_system_ready.py` - confirm 54 agents ready
- [ ] Execute simulation: 100+ transactions
- [ ] Monitor on Snowtrace
- [ ] Export to CSV
- [ ] Take screenshots of key transactions
- [ ] Write `2.4-DAY3-EXECUTION-RESULTS.md`

**Output:** 100+ transactions on-chain, data exported

### Day 4 (4 hours): Analysis
**Tasks:**
- [ ] Implement `scripts/analyze_ratings.py`
- [ ] Run statistical analysis
- [ ] Generate visualizations
- [ ] Create Jupyter notebook for interactive analysis
- [ ] Write `2.5-DAY4-ANALYSIS.md`

**Output:** Statistical findings documented

### Day 5 (4 hours): Document Edge Cases
**Tasks:**
- [ ] Identify 6+ interesting edge cases from data
- [ ] For each: document transaction hash, ratings, significance
- [ ] Take Snowtrace screenshots
- [ ] Write `2.6-DAY5-EDGE-CASES.md`
- [ ] Update progress tracker
- [ ] Write Week 2 summary

**Output:** Complete Week 2 package ready for EIP submission

---

## Questions to Confirm Before Proceeding

1. **Folder structure:** Does the proposed structure make sense?
2. **Scripts location:** `contribution/scripts/` is the right place?
3. **Dependencies:** Should we copy all of `/shared/` or just key files?
4. **Agent configs:** Should we reference agent .env files from main repo, or copy them too?
5. **Testing:** Should we create tests in `contribution/tests/` or reference main repo tests?
6. **Data export:** CSV format sufficient, or also JSON/SQLite?

---

## Next Steps (After Approval)

1. **Create folder structure** - Set up all directories
2. **Copy dependencies** - Get required files into contribution/
3. **Write simulation scenarios document** - Detail all 6 scenarios
4. **Create requirements.txt** - List all Python packages
5. **Implement verify_system_ready.py** - First script (simpler)
6. **Implement simulate_marketplace.py** - Main script
7. **Test with dry-run** - Verify everything works
8. **Execute transactions** - Run for real
9. **Analyze results** - Statistical analysis
10. **Document findings** - Complete Week 2

---

**Status:** ‚è∏Ô∏è WAITING FOR APPROVAL

**Please review this plan and confirm:**
- ‚úÖ Folder structure is correct
- ‚úÖ Script design makes sense
- ‚úÖ Execution plan is clear
- ‚úÖ Any changes needed

**Then I'll proceed with implementation!**
